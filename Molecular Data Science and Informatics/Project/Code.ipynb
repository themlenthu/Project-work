{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de77d14",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abba4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5ebe2",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "754d1b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded ESOL\n"
     ]
    }
   ],
   "source": [
    "esol_url = 'https://raw.githubusercontent.com/gsi-lab/GC-GNN/main/datasets/ESOL.csv'\n",
    "\n",
    "root = os.getcwd()\n",
    "esol_path = os.path.join(root,'esol.csv')\n",
    "\n",
    "if not os.path.exists(esol_path):\n",
    "    urllib.request.urlretrieve(esol_url, esol_path)\n",
    "print(\"Downloaded ESOL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bb7244d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Const_Value</th>\n",
       "      <th>ESOL_Value</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amigdalin</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fenfuram</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>-2.885</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citral</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>-2.579</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Picene</td>\n",
       "      <td>-7.87</td>\n",
       "      <td>-6.618</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thiophene</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>-2.232</td>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benzothiazole</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-2.733</td>\n",
       "      <td>c2ccc1scnc1c2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2,2,4,6,6'-PCB</td>\n",
       "      <td>-7.32</td>\n",
       "      <td>-6.545</td>\n",
       "      <td>Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Estradiol</td>\n",
       "      <td>-5.03</td>\n",
       "      <td>-4.138</td>\n",
       "      <td>CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dieldrin</td>\n",
       "      <td>-6.29</td>\n",
       "      <td>-4.533</td>\n",
       "      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rotenone</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>-5.246</td>\n",
       "      <td>COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  Const_Value  ESOL_Value  \\\n",
       "0       Amigdalin        -0.77      -0.974   \n",
       "1        Fenfuram        -3.30      -2.885   \n",
       "2          citral        -2.06      -2.579   \n",
       "3          Picene        -7.87      -6.618   \n",
       "4       Thiophene        -1.33      -2.232   \n",
       "5   benzothiazole        -1.50      -2.733   \n",
       "6  2,2,4,6,6'-PCB        -7.32      -6.545   \n",
       "7       Estradiol        -5.03      -4.138   \n",
       "8        Dieldrin        -6.29      -4.533   \n",
       "9        Rotenone        -4.42      -5.246   \n",
       "\n",
       "                                              SMILES  Family  \n",
       "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...     NaN  \n",
       "1                             Cc1occc1C(=O)Nc2ccccc2     NaN  \n",
       "2                               CC(C)=CCCC(C)=CC(=O)     NaN  \n",
       "3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43     NaN  \n",
       "4                                            c1ccsc1     NaN  \n",
       "5                                      c2ccc1scnc1c2     NaN  \n",
       "6                 Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl     NaN  \n",
       "7                   CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O     NaN  \n",
       "8     ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl     NaN  \n",
       "9    COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C     NaN  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esol_df = pd.read_csv(esol_path)\n",
    "esol_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c7c6ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ESOL_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "      <td>-0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "      <td>-2.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "      <td>-2.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "      <td>-6.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>-2.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>FC(F)(F)C(Cl)Br</td>\n",
       "      <td>-2.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>CNC(=O)ON=C(SC)C(=O)N(C)C</td>\n",
       "      <td>-0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>CCSCCSP(=S)(OC)OC</td>\n",
       "      <td>-3.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>CCC(C)C</td>\n",
       "      <td>-2.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>COP(=O)(OC)OC(=CCl)c1cc(Cl)c(Cl)cc1Cl</td>\n",
       "      <td>-4.320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMILES  ESOL_Value\n",
       "0     OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...      -0.974\n",
       "1                                Cc1occc1C(=O)Nc2ccccc2      -2.885\n",
       "2                                  CC(C)=CCCC(C)=CC(=O)      -2.579\n",
       "3                    c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43      -6.618\n",
       "4                                               c1ccsc1      -2.232\n",
       "...                                                 ...         ...\n",
       "1123                                    FC(F)(F)C(Cl)Br      -2.608\n",
       "1124                          CNC(=O)ON=C(SC)C(=O)N(C)C      -0.908\n",
       "1125                                  CCSCCSP(=S)(OC)OC      -3.323\n",
       "1126                                            CCC(C)C      -2.245\n",
       "1127              COP(=O)(OC)OC(=CCl)c1cc(Cl)c(Cl)cc1Cl      -4.320\n",
       "\n",
       "[1128 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = esol_df.loc[:,['SMILES','ESOL_Value']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab7802",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3193fee",
   "metadata": {},
   "source": [
    "### Attentive FP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15e5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import edge_softmax\n",
    "\n",
    "class Atom_AFPLayer(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = net_params['hidden_dim']\n",
    "        self.embedding_node_lin = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.embedding_edge_lin = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim + self.hidden_dim, self.hidden_dim, bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.cal_alignment = nn.Sequential(\n",
    "            nn.Dropout(net_params['dropout']),\n",
    "            nn.Linear(self.hidden_dim + self.hidden_dim, 1, bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.attend = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim, bias=True)\n",
    "        )\n",
    "        self.GRUCell = nn.GRUCell(self.hidden_dim, self.hidden_dim)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding_node_lin[0].reset_parameters()\n",
    "        self.embedding_edge_lin[0].reset_parameters()\n",
    "        self.cal_alignment[1].reset_parameters()\n",
    "        self.attend[0].reset_parameters()\n",
    "        self.GRUCell.reset_parameters()\n",
    "\n",
    "    def update_edge_by_neighbor(self, edges):\n",
    "        neighbor_message = self.embedding_edge_lin(torch.cat([edges.src['node_embedded_feats'], edges.data['edge_feats']], dim=-1))\n",
    "        return {'neighbor_message': neighbor_message}\n",
    "\n",
    "    def cal_alignment_score(self, edges):\n",
    "        alignment_score = self.cal_alignment(torch.cat([edges.data['neighbor_message'], edges.dst['node_embedded_feats']], dim=-1))\n",
    "        return {'score': alignment_score}\n",
    "\n",
    "    def att_context_passing(self, edges):\n",
    "        return {'mail': edges.data['att_context']}\n",
    "\n",
    "    def cal_context(self, nodes):\n",
    "        return {'context': torch.sum(nodes.mailbox['mail'], dim=-2)}\n",
    "\n",
    "    def forward(self, graph, node, edge):\n",
    "        graph = graph.local_var()\n",
    "        graph.ndata['node_feats'] = node\n",
    "        graph.ndata['node_embedded_feats'] = self.embedding_node_lin(graph.ndata['node_feats'])\n",
    "        graph.edata['edge_feats'] = edge\n",
    "\n",
    "        # update the edge feats by concat edge feats together with the neighborhood node feats\n",
    "        graph.apply_edges(self.update_edge_by_neighbor)\n",
    "        graph.apply_edges(self.cal_alignment_score)\n",
    "        graph.edata['att_context'] = edge_softmax(graph, graph.edata['score']) * self.attend(graph.edata['neighbor_message'])\n",
    "        graph.update_all(self.att_context_passing, self.cal_context)\n",
    "        context = F.elu(graph.ndata['context'])\n",
    "        new_node = F.relu(self.GRUCell(context, graph.ndata['node_embedded_feats']))\n",
    "        return new_node\n",
    "\n",
    "\n",
    "class Atom_AttentiveFP(nn.Module):\n",
    "    # Generate Context of each nodes\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.PassingDepth = nn.ModuleList([Atom_AFPLayer(net_params) for _ in range(net_params['depth'])])\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for l in self.PassingDepth:\n",
    "            l.reset_parameters()\n",
    "\n",
    "    def forward(self, graph, node, edge):\n",
    "        with graph.local_scope():\n",
    "            for step in self.PassingDepth:\n",
    "                node = step(graph, node, edge)\n",
    "        return node\n",
    "\n",
    "\n",
    "class Mol_AFPLayer(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.GRUCell = nn.GRUCell(net_params['hidden_dim'], net_params['hidden_dim'])\n",
    "\n",
    "        self.cal_alignment = nn.Sequential(\n",
    "            nn.Linear(net_params['hidden_dim'] + net_params['hidden_dim'], 1, bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.attend = nn.Sequential(\n",
    "            nn.Dropout(net_params['dropout']),\n",
    "            nn.Linear(net_params['hidden_dim'], net_params['hidden_dim'], bias=True)\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.GRUCell.reset_parameters()\n",
    "        self.cal_alignment[0].reset_parameters()\n",
    "        self.attend[1].reset_parameters()\n",
    "\n",
    "    def forward(self, graph, super_node, node):\n",
    "        graph = graph.local_var()\n",
    "        super_node = F.leaky_relu(super_node)\n",
    "\n",
    "        graph.ndata['score'] = self.cal_alignment(torch.cat([node, dgl.broadcast_nodes(graph, super_node)], dim=1))\n",
    "        graph.ndata['attention_weight'] = dgl.softmax_nodes(graph, 'score')\n",
    "        graph.ndata['hidden_node'] = self.attend(node)\n",
    "        super_context = F.elu(dgl.sum_nodes(graph, 'hidden_node', 'attention_weight'))\n",
    "        super_node = F.relu(self.GRUCell(super_context, super_node))\n",
    "        return super_node, graph.ndata['attention_weight']\n",
    "\n",
    "\n",
    "class Mol_AttentiveFP(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.MultiTimeSteps = nn.ModuleList([Mol_AFPLayer(net_params) for d in range(net_params['layers'])])\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for l in self.MultiTimeSteps:\n",
    "            l.reset_parameters()\n",
    "\n",
    "    def forward(self, graph, node):\n",
    "        with graph.local_scope():\n",
    "            attention_list = []\n",
    "            graph.ndata['hidden_node'] = node\n",
    "            super_node = dgl.sum_nodes(graph, 'hidden_node')\n",
    "            for step in self.MultiTimeSteps:\n",
    "                super_node, attention_t = step(graph, super_node, node)\n",
    "                attention_list.append(attention_t)\n",
    "            attention_list = torch.cat(attention_list, dim=1)\n",
    "        return super_node, attention_list\n",
    "\n",
    "\n",
    "class AttentiveFPNet(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.embedding_node_lin = nn.Sequential(\n",
    "            nn.Linear(net_params['num_atom_type'], net_params['hidden_dim'], bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.embedding_edge_lin = nn.Sequential(\n",
    "            nn.Linear(net_params['num_bond_type'], net_params['hidden_dim'], bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.Atom_Attentive = Atom_AttentiveFP(net_params)\n",
    "        self.Mol_Attentive = Mol_AttentiveFP(net_params)\n",
    "        self.linear_predict = nn.Sequential(\n",
    "            nn.Dropout(net_params['dropout']),\n",
    "            nn.Linear(net_params['hidden_dim'], 1, bias=True)\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.embedding_node_lin[0].reset_parameters()\n",
    "        self.embedding_edge_lin[0].reset_parameters()\n",
    "        for layer in self.linear_predict:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.reset_parameters()\n",
    "        self.Atom_Attentive.reset_parameters()\n",
    "        self.Mol_Attentive.reset_parameters()\n",
    "\n",
    "    def forward(self, graph, node, edge, get_descriptors=False, get_attention=False):\n",
    "        \"\"\"Graph-level regression\n",
    "        Parameters\n",
    "        ----------\n",
    "        graph : DGLGraph\n",
    "            DGLGraph for a batch of graphs.\n",
    "        node : float tensor of shape (V, F_n)\n",
    "            Input node features. V for the number of nodes, F_n for the size of node features.\n",
    "        edge : float tensor of shape (E, F_e)\n",
    "            Input edge features. E for the number of edges, F_e for the size of edge features.\n",
    "        Returns\n",
    "        ----------\n",
    "        output : float tensor of shape (G, 1)\n",
    "            Prediction for the graphs in the batch. G for the number of graphs.\n",
    "        graph : DGLGraph\n",
    "            DGLGraph for a batch of graphs with attribute 'attention_weights'.\n",
    "        \"\"\"\n",
    "        node = node.float()\n",
    "        edge = edge.float()\n",
    "        node = self.embedding_node_lin(node)\n",
    "        edge = self.embedding_edge_lin(edge)\n",
    "\n",
    "        new_node = self.Atom_Attentive(graph, node, edge)\n",
    "\n",
    "        super_node, attention_list = self.Mol_Attentive(graph, new_node)\n",
    "\n",
    "        output = self.linear_predict(super_node)\n",
    "        if get_attention:\n",
    "            graph.ndata['attention_weight'] = attention_list\n",
    "            attention_list_array = []\n",
    "            for g in dgl.unbatch(graph):\n",
    "                attention_list_array.append(g.ndata['attention_weight'].detach().to(device='cpu').numpy())\n",
    "            return output, attention_list_array\n",
    "        if get_descriptors:\n",
    "            return output, super_node\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "        #return output, attention_list\n",
    "\n",
    "    def loss(self, scores, targets):\n",
    "        loss = nn.MSELoss()(scores, targets)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class Linear_BatchNorm(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.L = nn.Linear(in_dim, out_dim, bias=True)\n",
    "        self.batchnorm_h = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden_input = self.L(input)\n",
    "        size = hidden_input.size()\n",
    "        hidden_input = hidden_input.view(-1, hidden_input.size()[-1], 1)\n",
    "        hidden_input = self.batchnorm_h(hidden_input)\n",
    "        output = hidden_input.view(size)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3becd61e",
   "metadata": {},
   "source": [
    "### Attentive Group Contribution (AGC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d945c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SingleHeadFragmentLayer(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.AtomEmbedding = Atom_AttentiveFP(net_params)\n",
    "        self.FragEmbedding = Mol_AttentiveFP(net_params)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.AtomEmbedding.reset_parameters()\n",
    "        self.FragEmbedding.reset_parameters()\n",
    "\n",
    "    def forward(self, frag_graph, frag_node, frag_edge):\n",
    "        # node_fragments: tensor: size(num_nodes_in_batch, num_features)\n",
    "        node_fragments = self.AtomEmbedding(frag_graph, frag_node, frag_edge)\n",
    "        super_frag, _ = self.FragEmbedding(frag_graph, node_fragments)\n",
    "        return super_frag\n",
    "\n",
    "\n",
    "class SingleHeadJunctionLayer(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.project_motif = nn.Sequential(\n",
    "            nn.Linear(net_params['hidden_dim'] + net_params['hidden_dim'], net_params['hidden_dim'], bias=True)\n",
    "        )\n",
    "        self.MotifEmbedding = Atom_AttentiveFP(net_params)\n",
    "        self.GraphEmbedding = Mol_AttentiveFP(net_params)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for l in self.project_motif:\n",
    "            if isinstance(l, nn.Linear):\n",
    "                l.reset_parameters()\n",
    "        self.MotifEmbedding.reset_parameters()\n",
    "        self.GraphEmbedding.reset_parameters()\n",
    "\n",
    "    def forward(self, motif_graph, motif_node, motif_edge):\n",
    "        motif_node = self.project_motif(motif_node)\n",
    "        new_motif_node = self.MotifEmbedding(motif_graph, motif_node, motif_edge)\n",
    "        super_new_graph, super_attention_weight = self.GraphEmbedding(motif_graph, new_motif_node)\n",
    "        return super_new_graph, super_attention_weight\n",
    "\n",
    "\n",
    "class AGCNet(nn.Module):\n",
    "    def __init__(self, net_params):\n",
    "        super().__init__()\n",
    "        self.embedding_frag_node_lin = nn.Sequential(\n",
    "            nn.Linear(net_params['num_atom_type'], net_params['hidden_dim'], bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.embedding_frag_edge_lin = nn.Sequential(\n",
    "            nn.Linear(net_params['num_bond_type'], net_params['hidden_dim'], bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.embedding_motif_node_lin = nn.Sequential(\n",
    "            nn.Linear(net_params['frag_dim'], net_params['hidden_dim'], bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.embedding_motif_edge_lin = nn.Sequential(\n",
    "            nn.Linear(net_params['num_bond_type'], net_params['hidden_dim'], bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.num_heads = net_params['num_heads']\n",
    "        self.fragment_heads = nn.ModuleList([SingleHeadFragmentLayer(net_params) for _ in range(self.num_heads)])\n",
    "        self.junction_heads = nn.ModuleList([SingleHeadJunctionLayer(net_params) for _ in range(self.num_heads)])\n",
    "\n",
    "        self.frag_attend = nn.Sequential(\n",
    "            nn.Linear(self.num_heads * net_params['hidden_dim'], net_params['hidden_dim'], bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.motif_attend = nn.Sequential(\n",
    "            nn.Linear(self.num_heads * net_params['hidden_dim'], net_params['hidden_dim'], bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.linear_predict = nn.Sequential(\n",
    "            nn.Dropout(net_params['dropout']),\n",
    "            nn.Linear(net_params['hidden_dim'], int(net_params['hidden_dim'] / 2), bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(int(net_params['hidden_dim'] / 2), 1, bias=True)\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for fragment_layer in self.fragment_heads:\n",
    "            fragment_layer.reset_parameters()\n",
    "        for junction_layer in self.junction_heads:\n",
    "            junction_layer.reset_parameters()\n",
    "        for layer in self.linear_predict:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer.reset_parameters()\n",
    "\n",
    "    def forward(self, origin_graph, origin_node, origin_edge, frag_graph, frag_node, frag_edge, motif_graph, motif_node, motif_edge, get_descriptors=False, get_attention=False):\n",
    "        \"\"\"Graph-level regression\n",
    "        Parameters\n",
    "        ----------\n",
    "        origin_graph : DGLGraph\n",
    "            DGLGraph for a batch of graphs (original).\n",
    "        origin_node : float tensor of shape (V, F_n)\n",
    "            Input node features in origin_graph. V for the number of nodes, F_n for the size of node features.\n",
    "        origin_edge : float tensor of shape (E, F_e)\n",
    "            Input edge features in origin_graph. E for the number of edges, F_e for the size of edge features.\n",
    "        frag_graph : DGLGraph\n",
    "            DGLGraph for a batch of graphs (fragment).\n",
    "        frag_node : float tensor of shape (V, F_n)\n",
    "            Input node features in fragments. V for the number of nodes, F_n for the size of node features.\n",
    "        frag_edge : float tensor of shape (E', F_e)\n",
    "            Input edge features in fragments. E' for the number of edges in fragments, F_e for the size of edge features.\n",
    "        motif_graph : DGLGraph\n",
    "            DGLGraph for a batch of graphs (motif).\n",
    "        motif_node : float tensor of shape (V_f, F_n)\n",
    "            Input node features in motif_graph. V_f for the number of fragments, F_n for the size of node features.\n",
    "        motif_edge : float tensor of shape (E_f, F_e)\n",
    "            Input edge features in motif_graph. E_f for the number of edges connecting fragments, F_e for the size of edge features.\n",
    "        Returns\n",
    "        ----------\n",
    "        output : float tensor of shape (G, 1)\n",
    "            Prediction for the graphs in the batch. G for the number of graphs.\n",
    "        motif_graph : DGLGraph\n",
    "            DGLGraph for a batch of graphs with attribute 'attention_weights' of fragments.\n",
    "        \"\"\"\n",
    "        # Fragments Layer:\n",
    "        frag_node = frag_node.float()\n",
    "        frag_edge = frag_edge.float()\n",
    "        frag_node = self.embedding_frag_node_lin(frag_node)\n",
    "        frag_edge = self.embedding_frag_edge_lin(frag_edge)\n",
    "        frag_heads_out = [frag_block(frag_graph, frag_node, frag_edge) for frag_block in self.fragment_heads]\n",
    "        graph_motif = self.frag_attend(torch.cat(frag_heads_out, dim=-1))\n",
    "        motif_graph.ndata['feats'] = graph_motif\n",
    "        # Junction Tree Layer:\n",
    "        #motif_node = motif_node.float()\n",
    "        motif_edge = motif_edge.float()\n",
    "        motif_node = self.embedding_motif_node_lin(motif_node)\n",
    "        motif_edge = self.embedding_motif_edge_lin(motif_edge)\n",
    "        motif_node = torch.cat([graph_motif, motif_node], dim=-1)\n",
    "        junction_graph_heads_out = []\n",
    "        junction_attention_heads_out = []\n",
    "        for single_head in self.junction_heads:\n",
    "            single_head_new_graph, single_head_attention_weight = single_head(motif_graph, motif_node, motif_edge)\n",
    "            junction_graph_heads_out.append(single_head_new_graph)\n",
    "            junction_attention_heads_out.append(single_head_attention_weight)\n",
    "\n",
    "        super_new_graph = torch.relu(torch.mean(torch.stack(junction_graph_heads_out, dim=1), dim=1))\n",
    "        super_attention_weight = torch.mean(torch.stack(junction_attention_heads_out, dim=1), dim=1)\n",
    "        output = self.linear_predict(super_new_graph)\n",
    "        #return output, motif_graph\n",
    "        if get_attention:\n",
    "            motif_graph.ndata['attention_weight'] = super_attention_weight\n",
    "            attention_list_array = []\n",
    "            for g in dgl.unbatch(motif_graph):\n",
    "                attention_list_array.append(g.ndata['attention_weight'].detach().to(device='cpu').numpy())\n",
    "            return output, attention_list_array\n",
    "        if get_descriptors:\n",
    "            return output, super_new_graph\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def loss(self, scores, targets):\n",
    "        loss = nn.MSELoss()(scores, targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8456c93",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17e797c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna\\IIT MADRAS\\Molecular Data Science and Informatics\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d270bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class Metrics(object):\n",
    "    def __init__(self, y, y_pred, p):\n",
    "        super().__init__()\n",
    "        self.RMSE = self.cal_RMSE(y, y_pred)\n",
    "        self.AIC = self.cal_AIC(y, y_pred, p)\n",
    "        self.BIC = self.cal_BIC(y, y_pred, p)\n",
    "        self.R2 = r2_score(y, y_pred)\n",
    "        self.MAE = MAE(y, y_pred)\n",
    "        self.SSE = self.cal_SSE(y, y_pred)\n",
    "        self.MAPE = MAPE(y, y_pred)\n",
    "        self.MaxErr = max_error(y, y_pred)\n",
    "        self.residual = y_pred - y\n",
    "\n",
    "    def cal_SSE(self, y, y_pred):\n",
    "        sum_squared = torch.sum((y - y_pred) ** 2)\n",
    "        return sum_squared.numpy()\n",
    "\n",
    "    def cal_RMSE(self, y, y_pred):\n",
    "        mean_squared = MSE(y, y_pred)\n",
    "        return sqrt(mean_squared)\n",
    "\n",
    "    def cal_AIC(self, y, y_pred, p):\n",
    "        n = len(y)\n",
    "        aic_score = n * np.log(MSE(y, y_pred)) + 2 * p\n",
    "        return aic_score\n",
    "\n",
    "    def cal_BIC(self, y, y_pred, p):\n",
    "        n = len(y)\n",
    "        bic_score = n * np.log(MSE(y, y_pred)) + p * np.log(n)\n",
    "        return bic_score\n",
    "\n",
    "    def cal_MaxErr(self, y, y_pred):\n",
    "        return torch.max(torch.abs(y - y_pred), dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdefffc9",
   "metadata": {},
   "source": [
    "# Aqueous solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a3dd0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dgl by featurizers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dgl\\heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently preparing molecule 100/1128\n",
      "Currently preparing molecule 200/1128\n",
      "Currently preparing molecule 300/1128\n",
      "Currently preparing molecule 400/1128\n",
      "Currently preparing molecule 500/1128\n",
      "Currently preparing molecule 600/1128\n",
      "Currently preparing molecule 700/1128\n",
      "Currently preparing molecule 800/1128\n",
      "Currently preparing molecule 900/1128\n",
      "Currently preparing molecule 1000/1128\n",
      "Currently preparing molecule 1100/1128\n",
      "Preparing fragmentation ...\n",
      "Currently proceeding fragmentation on molecule 100/1128\n",
      "Currently proceeding fragmentation on molecule 200/1128\n",
      "Currently proceeding fragmentation on molecule 300/1128\n",
      "Currently proceeding fragmentation on molecule 400/1128\n",
      "Currently proceeding fragmentation on molecule 500/1128\n",
      "Currently proceeding fragmentation on molecule 600/1128\n",
      "Currently proceeding fragmentation on molecule 700/1128\n",
      "Currently proceeding fragmentation on molecule 800/1128\n",
      "Currently proceeding fragmentation on molecule 900/1128\n",
      "Currently proceeding fragmentation on molecule 1000/1128\n",
      "Currently proceeding fragmentation on molecule 1100/1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 153:  51%|â–Œ| 153/300 [03:15<03:07,  1.28s/it, time=1.27, lr=0.00401, train_loss=0.0583, val_loss=0.12, test_loss=\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 162:  54%|â–Œ| 162/300 [03:32<03:00,  1.31s/it, time=1.31, lr=0.00401, train_loss=0.067, val_loss=0.125, test_loss=\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 202:  67%|â–‹| 202/300 [04:25<02:08,  1.32s/it, time=1.28, lr=0.00401, train_loss=0.0606, val_loss=0.0802, test_los\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 178:  59%|â–Œ| 178/300 [13:29<09:14,  4.55s/it, time=1.52, lr=0.00401, train_loss=0.059, val_loss=0.0817, test_loss\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 249:  83%|â–Š| 249/300 [05:19<01:05,  1.28s/it, time=1.27, lr=0.00321, train_loss=0.0541, val_loss=0.123, test_loss\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 169:  56%|â–Œ| 169/300 [03:41<02:51,  1.31s/it, time=1.35, lr=0.00401, train_loss=0.0633, val_loss=0.115, test_loss\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 297:  99%|â–‰| 297/300 [06:28<00:03,  1.31s/it, time=1.29, lr=0.00401, train_loss=0.0426, val_loss=0.103, test_loss\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 193:  64%|â–‹| 193/300 [04:08<02:17,  1.29s/it, time=1.26, lr=0.00401, train_loss=0.0543, val_loss=0.149, test_loss\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 299: 100%|â–ˆ| 300/300 [41:10<00:00,  8.24s/it, time=0.951, lr=0.00205, train_loss=0.0358, val_loss=0.0988, test_lo\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n",
      "Epoch 206:  69%|â–‹| 206/300 [03:18<01:30,  1.04it/s, time=0.88, lr=0.00401, train_loss=0.0569, val_loss=0.105, test_loss\n",
      "C:\\Users\\Krishna\\AppData\\Local\\Temp/ipykernel_6828/3317689477.py:160: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from src.feature.atom_featurizer import classic_atom_featurizer\n",
    "from src.feature.bond_featurizer import classic_bond_featurizer\n",
    "from src.feature.mol_featurizer import classic_mol_featurizer\n",
    "from utils.mol2graph import smiles_2_bigraph\n",
    "from utils.junctiontree_encoder import JT_SubGraph\n",
    "\n",
    "from utils.splitter import Splitter\n",
    "from utils.metrics import Metrics\n",
    "from utils.Earlystopping import EarlyStopping\n",
    "from data.csv_dataset import MoleculeCSVDataset\n",
    "from src.dgltools import collate_molgraphs, collate_fraggraphs\n",
    "from data.dataloading import import_dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.count_parameters import count_parameters\n",
    "\n",
    "from networks.DMPNN import DMPNNNet\n",
    "from networks.MPNN import MPNNNet\n",
    "from networks.AttentiveFP import AttentiveFPNet\n",
    "from networks.FraGAT import NewFraGATNet\n",
    "from networks.AGC import AGCNet\n",
    "from utils.piplines import train_epoch, evaluate, train_epoch_frag, evaluate_frag, PreFetch\n",
    "from utils.Set_Seed_Reproducibility import set_seed\n",
    "\n",
    "params = {}\n",
    "net_params = {}\n",
    "#params['Dataset'] = 'HFUS'\n",
    "params['init_lr'] = 10** -2.3\n",
    "params['min_lr'] = 1e-9\n",
    "params['weight_decay'] = 0\n",
    "params['lr_reduce_factor'] = 0.8\n",
    "params['lr_schedule_patience'] = 30\n",
    "params['earlystopping_patience'] = 50\n",
    "params['max_epoch'] = 300\n",
    "\n",
    "net_params['num_atom_type'] = 36\n",
    "net_params['num_bond_type'] = 12\n",
    "net_params['hidden_dim'] = 36\n",
    "net_params['num_heads'] = 1\n",
    "net_params['dropout'] = 0.2\n",
    "net_params['depth'] = 2\n",
    "net_params['layers'] = 2\n",
    "net_params['residual'] = False\n",
    "net_params['batch_norm'] = False\n",
    "net_params['layer_norm'] = False\n",
    "net_params['device'] = 'cpu'\n",
    "dataset_list = ['ESOL']\n",
    "\n",
    "\n",
    "for i in range(len(dataset_list)):\n",
    "    params['Dataset'] = dataset_list[i]\n",
    "    df, scaling = import_dataset(params)\n",
    "    cache_file_path = os.path.realpath('./cache')\n",
    "    if not os.path.exists(cache_file_path):\n",
    "        os.mkdir(cache_file_path)\n",
    "    cache_file = os.path.join(cache_file_path, params['Dataset'] + '_CCC')\n",
    "\n",
    "    error_path = os.path.realpath('./error_log')\n",
    "    if not os.path.exists(error_path):\n",
    "        os.mkdir(error_path)\n",
    "    error_log_path = os.path.join(error_path, '{}_{}'.format(params['Dataset'], time.strftime('%Y-%m-%d-%H-%M')) + '.csv')\n",
    "\n",
    "    fragmentation = JT_SubGraph(scheme='MG_plus_reference')\n",
    "    net_params['frag_dim'] = fragmentation.frag_dim\n",
    "    dataset = MoleculeCSVDataset(df, smiles_2_bigraph, classic_atom_featurizer, classic_bond_featurizer, classic_mol_featurizer, cache_file, load=False\n",
    "                                 , error_log=error_log_path, fragmentation=fragmentation)\n",
    "\n",
    "    splitter = Splitter(dataset)\n",
    "    set_seed(seed=1000)\n",
    "\n",
    "    rows = []\n",
    "    file_path = os.path.realpath('./output')\n",
    "    if not os.path.exists(file_path):\n",
    "        os.mkdir(file_path)\n",
    "    save_file_path = os.path.join(file_path, '{}_{}_{}'.format(params['Dataset'], 'AGCNet', time.strftime('%Y-%m-%d-%H-%M')) + '.csv')\n",
    "    df = pd.DataFrame(columns=['seed', 'train_R2', 'val_R2', 'test_R2', 'all_R2', 'train_MAE', 'val_MAE', 'test_MAE', 'all_MAE',\n",
    "                       'train_RMSE', 'val_RMSE', 'test_RMSE', 'all_RMSE'])\n",
    "    for i in range(0, 10):\n",
    "        seed = np.random.randint(1, 5000)\n",
    "        set_seed(seed=1000)\n",
    "        train_set, val_set, test_set, raw_set = splitter.Random_Splitter(seed=seed, frac_train=0.8, frac_val=0.1)\n",
    "\n",
    "        train_loader = DataLoader(train_set, collate_fn=collate_fraggraphs, batch_size=len(train_set), shuffle=False)\n",
    "        val_loader = DataLoader(val_set, collate_fn=collate_fraggraphs, batch_size=len(val_set), shuffle=False)\n",
    "        test_loader = DataLoader(test_set, collate_fn=collate_fraggraphs, batch_size=len(test_set), shuffle=False)\n",
    "        raw_loader = DataLoader(raw_set, collate_fn=collate_fraggraphs, batch_size=len(raw_set), shuffle=False)\n",
    "\n",
    "        fetched_data = PreFetch(train_loader, val_loader, test_loader, raw_loader, frag=True)\n",
    "        model = AGCNet(net_params).to(device='cpu')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=params['lr_reduce_factor'],\n",
    "                                                               patience=params['lr_schedule_patience'], verbose=False)\n",
    "        t0 = time.time()\n",
    "        per_epoch_time = []\n",
    "        early_stopping = EarlyStopping(patience=params['earlystopping_patience'], path='checkpoint_seed' + params['Dataset'] + 'AGC' + '.pt')\n",
    "\n",
    "        with tqdm(range(params['max_epoch'])) as t:\n",
    "            n_param = count_parameters(model)\n",
    "            for epoch in t:\n",
    "                t.set_description('Epoch %d' % epoch)\n",
    "                start = time.time()\n",
    "                model, epoch_train_loss, epoch_train_metrics = train_epoch_frag(model, optimizer, scaling,\n",
    "                                                                                fetched_data.train_iter, fetched_data.train_batched_origin_graph_list,\n",
    "                                                                                fetched_data.train_batched_frag_graph_list,\n",
    "                                                                                fetched_data.train_batched_motif_graph_list,\n",
    "                                                                                fetched_data.train_targets_list,\n",
    "                                                                                fetched_data.train_smiles_list,\n",
    "                                                                                fetched_data.train_names_list, n_param)\n",
    "                epoch_val_loss, epoch_val_metrics = evaluate_frag(model, scaling, fetched_data.val_iter, fetched_data.val_batched_origin_graph_list,\n",
    "                                                                  fetched_data.val_batched_frag_graph_list, fetched_data.val_batched_motif_graph_list,\n",
    "                                                                  fetched_data.val_targets_list, fetched_data.val_smiles_list,\n",
    "                                                                  fetched_data.val_names_list, n_param)\n",
    "                epoch_test_loss, epoch_test_metrics = evaluate_frag(model, scaling, fetched_data.test_iter,\n",
    "                                                                    fetched_data.test_batched_origin_graph_list,\n",
    "                                                                    fetched_data.test_batched_frag_graph_list,\n",
    "                                                                    fetched_data.test_batched_motif_graph_list,\n",
    "                                                                    fetched_data.test_targets_list, fetched_data.test_smiles_list,\n",
    "                                                                    fetched_data.test_names_list, n_param)\n",
    "\n",
    "                t.set_postfix({'time': time.time() - start, 'lr': optimizer.param_groups[0]['lr'],\n",
    "                               'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss, 'test_loss': epoch_test_loss,\n",
    "                               'train_R2': epoch_train_metrics.R2, 'val_R2': epoch_val_metrics.R2, 'test_R2': epoch_test_metrics.R2})\n",
    "                per_epoch_time.append(time.time() - start)\n",
    "\n",
    "                scheduler.step(epoch_val_loss)\n",
    "                if optimizer.param_groups[0]['lr'] < params['min_lr']:\n",
    "                    print('\\n! LR equal to min LR set.')\n",
    "                    break\n",
    "\n",
    "                early_stopping(epoch_val_loss, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    break\n",
    "        model = early_stopping.load_checkpoint(model)\n",
    "        _, epoch_train_metrics = evaluate_frag(model, scaling, fetched_data.train_iter, fetched_data.train_batched_origin_graph_list,\n",
    "                                               fetched_data.train_batched_frag_graph_list, fetched_data.train_batched_motif_graph_list,\n",
    "                                               fetched_data.train_targets_list, fetched_data.train_smiles_list, fetched_data.train_names_list,\n",
    "                                               n_param)\n",
    "        _, epoch_val_metrics = evaluate_frag(model, scaling, fetched_data.val_iter, fetched_data.val_batched_origin_graph_list,\n",
    "                                             fetched_data.val_batched_frag_graph_list, fetched_data.val_batched_motif_graph_list,\n",
    "                                             fetched_data.val_targets_list, fetched_data.val_smiles_list, fetched_data.val_names_list, n_param)\n",
    "        _, epoch_test_metrics = evaluate_frag(model, scaling, fetched_data.test_iter, fetched_data.test_batched_origin_graph_list,\n",
    "                                              fetched_data.test_batched_frag_graph_list, fetched_data.test_batched_motif_graph_list,\n",
    "                                              fetched_data.test_targets_list, fetched_data.test_smiles_list, fetched_data.test_names_list, n_param)\n",
    "        _, epoch_raw_metrics = evaluate_frag(model, scaling, fetched_data.all_iter, fetched_data.all_batched_origin_graph_list,\n",
    "                                             fetched_data.all_batched_frag_graph_list, fetched_data.all_batched_motif_graph_list,\n",
    "                                             fetched_data.all_targets_list, fetched_data.all_smiles_list, fetched_data.all_names_list, n_param)\n",
    "\n",
    "\n",
    "        row = pd.Series({'seed': seed, 'train_R2': epoch_train_metrics.R2, 'val_R2': epoch_val_metrics.R2,\n",
    "                         'test_R2': epoch_test_metrics.R2, 'all_R2': epoch_raw_metrics.R2,\n",
    "                         'train_MAE': epoch_train_metrics.MAE, 'val_MAE': epoch_val_metrics.MAE,\n",
    "                         'test_MAE': epoch_test_metrics.MAE, 'all_MAE': epoch_raw_metrics.MAE,\n",
    "                         'train_RMSE': epoch_train_metrics.RMSE, 'val_RMSE': epoch_val_metrics.RMSE,\n",
    "                         'test_RMSE': epoch_test_metrics.RMSE, 'all_RMSE': epoch_raw_metrics.RMSE})\n",
    "        df = df.append(row, ignore_index=True)\n",
    "\n",
    "    df.to_csv(save_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652b1e3",
   "metadata": {},
   "source": [
    "## Predictions and Attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1307d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.piplines import evaluate_frag_attention\n",
    "\n",
    "train_pred, train_atten = evaluate_frag_attention(model, scaling, fetched_data.train_iter, fetched_data.train_batched_origin_graph_list,\n",
    "                                                                                fetched_data.train_batched_frag_graph_list,\n",
    "                                                                                fetched_data.train_batched_motif_graph_list)\n",
    "\n",
    "val_pred, val_atten = evaluate_frag_attention(model, scaling, fetched_data.val_iter, fetched_data.val_batched_origin_graph_list,\n",
    "                                                                                fetched_data.val_batched_frag_graph_list,\n",
    "                                                                                fetched_data.val_batched_motif_graph_list)\n",
    "\n",
    "test_pred, test_atten = evaluate_frag_attention(model, scaling, fetched_data.test_iter, fetched_data.test_batched_origin_graph_list,\n",
    "                                                                                fetched_data.test_batched_frag_graph_list,\n",
    "                                                                                fetched_data.test_batched_motif_graph_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "984b07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_train = torch.cat(fetched_data.train_targets_list,dim=0)\n",
    "train_target = scaling.ReScaler(target_list_train.detach().to(device='cpu').numpy())\n",
    "\n",
    "target_list_val = torch.cat(fetched_data.val_targets_list,dim=0)\n",
    "val_target = scaling.ReScaler(target_list_val.detach().to(device='cpu').numpy())\n",
    "\n",
    "target_list_test = torch.cat(fetched_data.test_targets_list,dim=0)\n",
    "test_target = scaling.ReScaler(target_list_test.detach().to(device='cpu').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a56a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_target.reshape(902,)\n",
    "train_pred = train_pred.reshape(902,)\n",
    "val_target = val_target.reshape(112,)\n",
    "val_pred = val_pred.reshape(112,)\n",
    "test_target = test_target.reshape(114,)\n",
    "test_pred = test_pred.reshape(114,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "07574309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'Target':train_target, 'Predict':train_pred})\n",
    "df_val = pd.DataFrame({'Target':val_target, 'Predict':val_pred})\n",
    "df_test = pd.DataFrame({'Target':test_target, 'Predict':test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1b68ccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>-1.460</td>\n",
       "      <td>-1.382201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-2.360</td>\n",
       "      <td>-2.493675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>-2.878</td>\n",
       "      <td>-2.987362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>-3.660</td>\n",
       "      <td>-3.748746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-3.953</td>\n",
       "      <td>-3.863875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target   Predict\n",
       "897  -1.460 -1.382201\n",
       "898  -2.360 -2.493675\n",
       "899  -2.878 -2.987362\n",
       "900  -3.660 -3.748746\n",
       "901  -3.953 -3.863875"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c7636dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-4.150</td>\n",
       "      <td>-3.773423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-0.830</td>\n",
       "      <td>-1.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-3.290</td>\n",
       "      <td>-3.300147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-4.800</td>\n",
       "      <td>-4.484435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-2.154</td>\n",
       "      <td>-2.674221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target   Predict\n",
       "107  -4.150 -3.773423\n",
       "108  -0.830 -1.277600\n",
       "109  -3.290 -3.300147\n",
       "110  -4.800 -4.484435\n",
       "111  -2.154 -2.674221"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6afa1814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-9.150001</td>\n",
       "      <td>-8.614853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-5.720000</td>\n",
       "      <td>-5.082323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.090296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-3.760000</td>\n",
       "      <td>-2.925282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-6.637000</td>\n",
       "      <td>-6.274870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target   Predict\n",
       "109 -9.150001 -8.614853\n",
       "110 -5.720000 -5.082323\n",
       "111  1.120000  1.090296\n",
       "112 -3.760000 -2.925282\n",
       "113 -6.637000 -6.274870"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb6988",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b8054",
   "metadata": {},
   "source": [
    "### Parity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b6b3ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity(df_train, df_val, df_test, x_label, ylabel, path):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.plot(df_train['Target'], df_train['Predict'], 'bo', label='train')\n",
    "    ax.plot(df_val['Target'], df_val['Predict'], 'ro', label='val')\n",
    "    ax.plot(df_test['Target'], df_test['Predict'], 'co', label='test')\n",
    "    ax.plot(np.concatenate((df_train['Target'], df_val['Target'], df_test['Target'])),\n",
    "            np.concatenate((df_train['Target'], df_val['Target'], df_test['Target'])), 'k-')\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    #fig.savefig('parity_plot', bbox_inches='tight', format='png', dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ea4d4849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dire = os.path.realpath('./plots')\n",
    "if not os.path.exists(dire):\n",
    "    os.mkdir(dire)\n",
    "\n",
    "x_label = 'Aq. sol. experimental'\n",
    "y_label = 'Aq. sol. predicted'\n",
    "parity(df_train, df_val, df_test, x_label, y_label, dire)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
